%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter4.tex
%% NOVA thesis document file
%%
%% Chapter with lots of dummy text
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE chapter4.tex}%

\chapter{System Design}
\label{cha:design}

\section{Discussion} % (fold)
\label{sec:discussion}

Recall that the problem at hand is how to make the process of updating contracts in
microservice-based systems more robust, in the sense that it should be harder to deploy a service that could
potentially break the system soundness.
There are many approaches to solve this problem, each with its own set of compromises.
The requirements that guided the design of the system, are outlined below by their priority:
\begin{itemize}
    \setlength\itemsep{0em}
    \item No downtime when upgrading service contracts;
    \item Automatic validation of the safety of deployment operations;
    \item Supporting all types of contract changes;
    \item Integration with existing tools and workflows;
    \item Minimize conception and maintenance effort;
    \item Consumer and producer services ignorant to the presence of proxy adapters;
    \item Transactionless deployment of upgrades to service contracts;
    \item No overhead when services communicate using the same contract version.
\end{itemize}

Four criteria were considered when evaluating each approach:
\textbf{Flexibility} the applicability of the approach under diverse scenarios;
\textbf{Effectiveness} the efficiency of an approach at solving a problem;
\textbf{Utility} the effort required to adopt and maintain the approach;
\textbf{Performance} the overhead associated with approach.

In the prototype's design, it was prioritized utility above performance because:
in the common case, it is expected for most service's to communicate via up-to-date contracts, messages will only need adaptation during a transitory period;
the performance overhead remains roughly static under diverse contract changes, as it is largely attributable to communication costs.
It was also prioritized flexibility and effectiveness above other criteria because if an approach isn't applicable or effective under a scenario,
then it will be necessary to adopt hybrid approaches, which will have a detrimental effect on the utility of the entire solution.

\section{Design Aspects} % (fold)
\label{sec:design_aspects}

\subsection{Communication Protocol} % (fold)
\label{sec:communication_protocol}

The communication protocol defines the syntax, semantics and synchronization of communication between microservices.
The choice in the communication protocol is bounded by the adopted communication strategy between microservices, orchestration or choreography.
Orchestration relies on request-response protocols while choreography relies on event-driven protocols.

\paragraph{Approach:}
It was chosen to design the system around the orchestration pattern and the HTTP protocol,
because most applications require a web presence and microservice systems that
rely on choreography still require the HTTP request-response protocol to support external consumers.

\paragraph{Alternatives:}
If choreography was adopted, the approach would need to support an additional communication protocol with different a contract structure and syntax.
It is complex to implement a generic approach that can handle multiple types of communication protocol's.
Other event-driven and request-response protocols, such as RPC, have contracts with a simplified
syntax and structure.
There are already a number of tools that support the evolution of contracts under these protocols, albeit with some limitations.

\subsection{Contract Specification} % (fold)
\label{sec:contract_specification}

It is required that each microservice’s interface be
described in a high-level language which abstracts away implementation details, because it is common
for microservices to be implemented under different frameworks and programming languages.
Additionally the contract specification of a service also includes information about its dependencies, and the necessary computational resources to support its operation.

\paragraph{Approach:}
The contract is composed by two distinct manifests.
In the first manifest the capabilities of a service are specified using the conventional approach of a Web API description language.
In the second manifest the service dependencies and hardware requirements are documented with a distinct description language.
The contract is divided into separate manifests, because external consumers are only interested on the documentation of the capabilities of a service,
and because it may be problematic to disclose information about hardware requirements.

To reduce the documentation effort only the dependencies between services are document, the dependencies between service procedures are not specified (eg. Service A in version 1.0 depends on service B in version 2.0).
One drawback of not documenting dependencies at the procedure level is that it is not possible to detect procedures that are unused by other services.
The installation of adapters is unnecessary in cases where only unused procedures are updated in a contract.
This case is expected to be rare, and having unused procedures in a microservice is undesirable due to API bloat.
The specification of inter-service dependencies is sufficient to ensure the safety of deployment operations.
The documentation of inter-procedure dependencies can be useful in API management tools,
these dependencies can be discovered indirectly via the alternative approach presented below.

\paragraph{Alternatives:}
Dependencies can be determined automatically by inspecting request logs between services.
The advantage of this approach is the reduced documentation effort, but it comes at a cost because
it is no longer possible to validate the safety of service deployments, since the dependencies of a service are unknown when it is deployed.
With this approach it is only possible to validate the safety of the removal of services that have been running over a long enough period of time.

\subsection{Supported Contract Evolutions} % (fold)
\label{sec:supported_contract_changes}

An HTTP contract is composed by procedures, each of which contains one request message and up to N response messages.

Response messages are composed by a status code and parameters.
The same status code cannot be shared across multiple response messages.
A response message's parameters can be placed in one of three places: headers, cookies, or body.

Request messages, on the other hand, are composed by an endpoint and parameters.
The endpoint is comprised by an HTTP method, a domain, and a sequence of path segments.
The parameters of a request message can be placed in two additional locations: path or query.
Only body parameters can have object or collection types.
Other parameter groups are limited to using primitive types (string, number, boolean).

All the contract elements mentioned above can be subject to change's as the contract evolves.
Multiple types of changes can also occur simultaneously in the same contract evolution.
\begin{itemize}
    \setlength\itemsep{0em}
    \item [A taxonomy of all conceivable HTTP contract evolutions is presented bellow:]
    \item [\textbf{Functional evolutions:}]
    \item Adding/removing a parameter.
    \item Adding/removing a response message from a procedure.
    \item Adding/removing a procedure.
    \item [\textbf{Semantic evolutions:}]
    \item Changing the type of parameter. \\ \textit{(eg. turning a integer field into a string)}
    \item Changing the HTTP method of an endpoint.
    \item Changing the status code of a response.
    \item [\textbf{Syntactic evolutions:}]
    \item Renaming a parameter.
    \item Migrating a parameter into a different location. \\ \textit{(eg. converting a path parameter into a field of the request's body schema)}
    \item Changing the format of a parameter. \\ \textit{(eg. modifying the format of a date)}
    \item Splitting a parameter into N different parameter. \\ \textit{(eg. dividing a name field into first and last name)}
    \item Merging parameters into a single parameter.
    \item Changing the path of an endpoint.
    \item [\textbf{Architectural evolutions:}]
    \item Splitting a procedure into N different procedures.
    \item Merging N procedures into a single procedure.
\end{itemize}

\paragraph{Approach:}
Of all the stated contract evolutions, the only changes that aren't directly supported are architectural evolutions.

Supporting the division of a procedure into multiple procedures is complex because the adapter would have to use distributed transactions to handle the independent failures of each new procedure.
Combining multiple procedures into a single procedure is also costly because the adapter must be stateful and session based to support this change.
The requests of the affected procedures would need to be stored in the adapter before they could be merged and sent through the new endpoint.
Furthermore, these two types of evolution are cumbersome to be documented in a description language, because the language would need to relate procedures in an $N\rightarrow 1$ and $1\rightarrow N$ relationships.

Alternatively, architectural evolutions can be converted into equivalent functional evolution's that keep the deprecated procedures in the contract alongside the new procedures.

\subsection{Specification of Contract Evolutions} % (fold)
\label{sec:evolution_specification}

It is not always possible to implicitly deduce the evolutions in a contract when comparing a new version to a prior version
(for example, renaming field $A$ to $B$ is indistinguishable, from inserting a new field $B$ and removing a field $A$ of the same type).
The developer must declare explicitly which evolution occurred.

\paragraph{Approach:}
Contract evolutions are specified in a manifest file, complete with its own syntax and rules,
which outlines how to adapt calls between two versions of a contract.
In this file all mappings between elements in each version are explicitly defined.
A mapping for one element can fall into one of three types:
\begin{itemize}
    \setlength\itemsep{0em}
    \item \textbf{Default value}: The developer provides a default value for the element.
    This mapping is only valid if the default value has the same type and format as the element.
    \item \textbf{Link}: The developer indicates that element A on the previous contract is equivalent to element B in the new contract.
    This mapping is only valid if the two elements have the same type and format.
    \item \textbf{Function}: The developer applies a function over $X_{n}$ elements of previous contract and indicates that the result of the function is equivalent to element Y in the new contract.
    This mapping is only valid if the function's output type and format are equal to element Y and if the function's arguments match the type and format of the provided  $X_{n}$ elements.
\end{itemize}
Depending on the API evolution a different mapping type is used:
renamed fields in contracts are supported with the usage of links;
the addition of new fields in contracts is supported with the use of default values;
complex contract changes, such as changing the format of a date are supported with the use of functions.

Additionally, procedures of a previous contract that are unused can be declared as obsolete in cases where there functionality is no longer needed.
Procedures that are obsolete don't need to be adapted by the proxy component.

\paragraph{Alternatives:}
The evolution specification is defined alongside the contract specification in the same manifest file.
Most web API specification languages already support default values and name aliases.
With these two features it would be straightforward
to document the following contract evolutions: renamed/addition/removal of fields.
This alternative may seem appealing for simpler contracts, but it becomes impractical as the number of revisions and consumers in prior versions rises.
This approach clutters service contract's with information that is irrelevant to consumers, and makes the specification of complex contract evolutions more cumbersome.

\subsection{Compatibility Verification} % (fold)
\label{sec:compatibility_verification_design}

TODO inconsistent

Intuitively, compatibility verification determines whether
all the edited elements in a producer contract are compatible with the ones effectively
used by the consumer services, and whether the new contract requirements are met
by the system’s existing resources.

\paragraph{Approach:}
The verification procedure used examines both the producer contract and all consumer references to determine the safety of a deployment operation.
Edited elements are considered compatible if the information supplied by prior elements is sufficient to meet the edited elements parameters.
Contract requirements are fulfilled if there are enough computational resources to accommodate the service and if all the
service dependencies are available and reachable in the system.

\paragraph{Alternatives:}
Instead of determining if a new contract version is compatible with all consumer references,
it is evaluated only whether the new contract is compatible with the prior contract versions that are still being consumed.
If a new contract is missing a procedure that was present in a prior version,
the developers will need to verify if the procedure is not being consumed
and mark it as obsolete in the evolution manifest for the contract to be considered safe.
This approach has the advantage of streamlining the verification process by eliminating the
need for all contracts to be accessible by machine code in a standardized fashion.
The downside is that it introduces human error in the verification of un-utilized service capabilities.

\subsection{Adapter Location} % (fold)
\label{sec:adapter_location}

The adaptation of messages is supported at runtime by a generated proxy component
that dynamically adapts the data exchanged between services.
The adapter can be deployed and intercept messages in different points through the exchange.

\paragraph{Approach:}
The adapters are installed as side-car container on the same node as the producer service container.
Consumers direct their requests based on the expected version of the service using a routing rule.
If the expected version matches the current service version, the request is answered directly by the service;
otherwise, the request is redirected through the adapter.
Since the adapter and the service are in the same node, the communication cost is expected to be comparable to the cost of inter-process message passing.
The main benefit of this approach is that the adapter can be deployed alongside the service,
which circumvents distributed transactions in deployments,
because container orchestrations tools such as Kubernetes allow the deployment of closely related containers as atomic units known as "pods".

\paragraph{Alternatives:}
An option, is to have the generated adapter code embedded in the service implementation.
This approach is expected to have higher performance than the previous approach since
the adapter would use function calls instead of inter-process calls, and because message serialization and de-serialization would be unnecessary.
The downside of this approach is that it would entail the modification of the service's code, which is problematic because each service can be implemented in a different framework and programming language.

In another option, the adapter can be installed on the nodes of all the consumers of a producer service.
This approach is problematic because a service upgrade would entail the re-deployment of all consumers.
If one of the consumer re-deployments fails, the entire service upgrade would have to be cancelled;
this is only achievable with the use of distributed transactions, which are inherently complex.
The re-deployment of consumers pods due to the installation of adapters can be avoided with the use of mobile code that is provided by the producer in a dedicated endpoint
(for example, this could be accomplished in Java with the use of network class loaders).
This approach is ineffective because it provides no benefits and requires more resources than the alternatives, since
instead of one adapter, N adapters would be needed, one in each consumer.

\subsection{Adapter Coverage} % (fold)
\label{sec:adapter_polymorphism}

The adapter can have a generic implementation that is able to adapt messages from any service, or it can
have a direct implementation that can only manage the adaptation of messages for a single service.

\paragraph{Approach:}
The adapter implementation is derived from a template implementation,
that is completed with code generated from evolution specification manifest file.
The advantage of this approach is that the implementation will be more performant than generic approaches.

\paragraph{Alternatives:}
The adapter has a generic implementation that is initialized with the data parsed from evolution specification files.
The correct adaptation procedure for a message is determined by inspecting specialized headers in the
message that indicate the message type, service and version.
The advantage of this approach is that a single adapter can convert messages from any service as long as the evolution manifests are supplied to the adapter beforehand.
This approach will consume fewer computational resources, in scenarios where the number of messages that require adaptation is low and uniformly distributed across all services,
because a single adapter can handle the load of all requests, whereas the alternative requires one adapter per service.
The disadvantage of this approach is that it requires modifications on the consumer's implementation to include message headers indicating the expected version of the producer service.

\subsection{Message Routing} % (fold)
\label{sec:message_routing}

Messages will need to reach either the application or the adapter, depending on the consumer expected contract, and the current producer contract.
Only messages that require adaptation should be forwarded through the adapter to reduce the adapter's load and resource consumption.

\paragraph{Approach:} The application and adapter servers of a microservice are accessible internally inside a cluster via distinct Kubernetes (K8s) services.
A K8s service, is an abstraction that defines a policy for accessing a logical set of containers under a single network address.
For each version of a service contract a distinct K8s service is created with the corresponding service name and contract version.
The address of each K8s service is discoverable via an internal DNS server.

When a microservice is upgraded, it's K8s services are refreshed with the new addresses of the application and adapter containers.
The K8s service that previously pointed to the application containers, will now point to the adapter containers, and
a new K8s service is created to support the new contract.
All consumers of the previous contract will begin forwarding their requests to the adapter container's rather than the application containers.

Consumers that only use unaffected procedures in the contract evolution don't need to direct their calls through the adapter.
If optimal performance and resource consumption is desired,
such consumer services will have to be updated and redeployed with the new producer DNS name, in order for their calls to be redirected to the application servers.

The redeployment of consumers in the former case can be avoided, if consumers participate in the contract evolution process.
The adapter server includes a header in responses that contains the address of the application server, and that indicates if a request required adaptation.
If the request didn't require modifications, consumer services begin to forward the request to the application server instead of the adapter.
With this approach consumer services are no longer unaware of the existence of proxy adapters,
and will need to use different addresses when calling different procedures of the same producer.

\paragraph{Alternatives:}
A reverse proxy like Nginx~\cite{nginx} could be used to route only the messages that require adaptation through the adapter.
With this approach all requests are forwarded through reverse proxy and redirected based on custom routing rules.
The routing rules are installed and updated when contract implementations are deployed.
This approach is counter-productive since it necessitates an additional reverse proxy server,
which will use roughly the same computational resources and add the same latency as the adapter server.

\subsection{Adapter Management} % (fold)
\label{sec:adapter_management}

The management of adapters should be automated similarly to the management of services.
In this section, it is discussed how to conciliate the operations related to the management of adapters with the more common operations of service deployment and upgrade.

\paragraph{Approach:}
During normal operation the adapters don't require any type of management other than monitoring,
adapters components only need to be provisioned during the upgrade of service contracts.
A contract upgrade is supported by the re-deployment of the impacted microservice, which is often managed via a continuous deployment pipeline.

The operations of contract compatibility verification, adapter generation, deployment,
and removal are introduced as additional stages in typical continuous deployment pipelines.

\subsection{API Management Tools} % (fold)
\label{sec:tools}

In distributed systems there is a lack of tools
comparable to those used in centralized systems, for visualizing the impact of a change and effort required to implement it.
In this section, it is discussed how such tools could be implemented.

\paragraph{Approach:}
Since all service contracts declare their dependencies on other services, the impact of change can be evaluated at a macroscopic level by
iterating thorough all contracts of the active services and verifying whether the changed service is being consumed.
Service contracts are stored in a version control system, with semantic versioning, where
each major version represents incompatible contract changes and minor versions represent backwards compatible contract changes.
The active services are discovered by querying the deployed services in the container orchestration tool.

\paragraph{Alternatives:}
Information collected about dependencies between procedures can be translated into an ontology language \cite{ontology} and stored in a registry.
The main advantage of this approach is that the registry can be integrated with a reasoning system capable of performing deductive inferences, such as
seeing the impact of a service failure across the system, and the resulting cascading failures.
This approach delivers fine-grained data about impact of contract changes and reduces the burden in the development of other API management tools.
This approach has not been explored because it falls outside the scope of this thesis, and can be used as complementary solution to the previous approach.

