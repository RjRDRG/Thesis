%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter4.tex
%% NOVA thesis document file
%%
%% Chapter with lots of dummy text
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE chapter4.tex}%

\chapter{System Design}
\label{cha:design}

In this chapter, we present the design of our system and discuss alternatives to the decisions we took in our implementation.
We dedicate the first half of this chapter to define the goals that guided the design of the system,
the remainder of the chapter will be used to discuss each design aspect in turn.

\section{Discussion} % (fold)
\label{sec:discussion}

Recall that the problem we are trying to solve is how to make the process of updating contracts in
microservice-based systems more robust, in the sense that it should be harder to deploy a service that could
potentially break the system soundness.
There are many approaches to solve this problem, each with its own set of compromises.
The requirements that guided the design of system, are outlined below by their priority:

\begin{itemize}
    \item No downtime when upgrading service contracts
    \item Supporting all types of contract changes
    \item Integration with existing tools and workflows
    \item Minimize conception and maintenance effort
    \item Automatic validation of the safety of deployment operations
    \item Consumer and producer services are ignorant to the presence of proxy adapters
    \item Transactionless deployment of upgrades to service contracts
    \item No overhead when services communicate using the same contract version
\end{itemize}

Four criteria were considered when evaluating each approach:
\textbf{Flexibility} the applicability of the approach under diverse scenarios;
\textbf{Effectiveness} the efficiency of an approach at solving a problem;
\textbf{Utility} the effort required to adopt and maintain the approach;
\textbf{Performance} the overhead associated with approach.

In the prototype's design, it was prioritized utility above performance because:
in the common case, it is expected for most service's to communicate via up-to-date contracts, service functionalities will only need adaptation during a transitory period;
the performance overhead remains roughly static under diverse contract changes, as it is largely attributable to communication costs.
It was also prioritized flexibility and effectiveness above other criteria because if an approach isn't applicable or effective under a scenario,
then it will be necessary to adopt hybrid approaches, which will have a detrimental effect on the utility of the entire solution.

\section{Design Aspects} % (fold)
\label{sec:design_aspects}

\subsection{Communication Protocol} % (fold)
\label{sec:communication_protocol}

The communication protocol defines the syntax, semantics and synchronization of communication between microservices.
The choice in the communication protocol is bounded by the adopted communication strategy between microservices, orchestration or choreography.
Orchestration relies on request-response protocols while choreography relies on event-driven protocols.

\paragraph{Approach:}
It was chosen to design the system around the orchestration pattern and the HTTP protocol,
because most applications require a web presence and microservice systems that
rely on choreography still require the HTTP request-response protocol to have a web presence.

\paragraph{Alternatives:}
If choreography was adopted, the approach would need to support an additional communication protocol with different a contract structure and syntax.
It is complex to implement a generic approach that supports all types of communication protocol's, because different protocol's can have different communication strategies.
It is preferable to extend the solution with modules designed to support specific protocol's.

Other event-driven and request-response protocols, such as RPC, have contracts with a simplified
syntax and structure, there are already a number of tools that support the evolution of contracts
under these protocols, albeit with some limitations.

\subsection{Contract Specification} % (fold)
\label{sec:contract_specification}

It is required that each microservice’s interface be
described in a high-level language which abstracts away implementation details, because it is common
for microservices to be implemented under different frameworks and programming languages.
Contract specifications are used to clearly define and document the capabilities of a service, its inter-service dependencies and the necessary computational resources to support its operation.

\paragraph{Approach:}
The capabilities of a service where specified using the conventional approach of a Web API description language.
Since it may be problematic to disclose service dependencies and computational requirements to external unsupervised consumers,
a separate manifest with a distinct description language is used to define and document this information.

The definition of the dependencies is done from the perspective of services.
In other words, the dependencies between service procedures are not documented, only the dependencies between services.
If the dependencies of each procedure individually are mapped, it's possible to detect procedures that are un-used internally by other services.
With this method, the installation of unnecessary adapters can be avoided in cases where only unreferenced or unused procedures are updated;
this case is expected to be very uncommon, and having unused procedures in a microservice is undesirable due to API bloat,
so the documentation is not worth the effort, specifying dependencies at the service level is sufficient.

\paragraph{Alternatives:}
Services dependencies can be determined indirectly by automatically inspecting request logs between services.
The advantage of this approach is the reduced documentation effort, but it comes at a cost because
it is no longer possible to validate the safety of service deployments, since the dependencies of a service are unknown when it is deployed or upgraded;
it is only possible to validate the safety of the removal of services after they have been running over a long enough period,
and even then there could be very rare calls between services that are not mapped by this method, these calls would make removals unsafe.
Un-needed adapters would also have to be removed manually by developers or through an automated inactivity-based warning system.

This approach could be employed with a different goal: mapping procedure dependencies.
When a breaking change occurs, this information can be used to discover impacted procedures, rather than just the impacted services.

\subsection{Compatibility Verification} % (fold)
\label{sec:compatibility_verification_design}

Intuitively, compatibility verification determines whether
all the edited elements in a producer service contract are compatible with the ones effectively
used by the consumer services, and whether the new contract requirements are met
by the system’s existing resources.

\paragraph{Approach}
The verification procedure used examines both the producer contract and all consumer references to determine the safety of a deployment operation.
Edited elements are considered compatible if the information supplied by prior elements is sufficient to meet the edited elements parameters.
Contract requirements are fulfilled if there are enough computational resources to accommodate the service and if all the
service dependencies are available and reachable in the system.

\paragraph{Alternative}
Instead of determining if a new contract version is compatible with all consumer references,
it is evaluated only whether the new contract is compatible with the prior versions that are still in use.
If a new contract is missing a capability that was present in a prior version,
the developers will need to verify if the capability is not being consumed
and mark it as obsolete in the evolution manifest for the contract to be considered safe.
This approach has the advantage of streamlining the verification process by eliminating the
need for all contracts to be accessible by machine code in a standardized fashion.
The downside is that it introduces human error in the verification of un-utilized service capabilities.

\subsection{API Management Tools} % (fold)
\label{sec:tools}

In distributed systems there is a lack of tools
comparable to those used in centralized systems, for visualizing the impact of a change and effort required to implement it.
In this section, we discuss how such tools could be implemented.

\paragraph{Approach:}
Since all service contracts declare their dependencies on other services, determining the impact of change in a procedure is as simple as
looping over all active services contracts and verifying whether the changed service is being consumed.
Service contracts are stored in a version control system, with semantic versioning, where
each major version represents incompatible contract changes and minor versions represent backwards compatible contract changes.
The active services are discovered by querying the deployed services in the container orchestration tool.

\paragraph{Alternatives:}
Information collected about the active services and dependencies between procedures can be translated into an ontology language and stored in a registry.
The main advantage of this approach is that the registry can be integrated with a reasoning system capable of performing deductive inferences, such as
seeing the impact of a service failure across the system, and the resulting cascading failures.
This approach delivers richer data and reduces the burden in the development of other API management tools,
however, this approach falls outside the scope of this thesis and has not been explored.

\subsection{Evolution Specification} % (fold)
\label{sec:evolution_specification}

It is not always possible to implicitly deduce the evolutions in a contract when comparing a new version to a prior version
(for example, renaming field \textbf{A} to \textbf{B} is indistinguishable, from inserting a new field \textbf{B} and removing a field of the same type \textbf{A}).
The developer must declare which evolution occurred explicitly.

\paragraph{Approach:}
The evolutions are specified in a manifest file, complete with its own syntax and rules,
which outlines how to adapt calls between two versions of a contract.
In this file all mappings between elements in each version are explicitly defined.
A mapping for one element can fall into one of three types:
\begin{itemize}
    \item \textbf{Default value}: The developer provides a default value for the element.
    This mapping is only valid if the default value has the same type and format as the element.
    \item \textbf{Link}: The developer indicates that element X on the previous contract is equivalent to element Y in the new contract.
    This mapping is only valid if the two elements have the same type and format.
    \item \textbf{Function}: The developer applies a function over Xn elements of previous contract and indicates that the result of the function is equivalent to element Y in the new contract.
    This mapping is only valid if the function's output type and format are equal to element Y and if the function's arguments match the type and format of the provided Xn elements.
\end{itemize}
Depending on the API evolution a different mapping type is used:
renamed fields in contracts are supported with the usage of links;
the addition of new fields in contracts is supported with the use of default values;
complex contract changes, such as changing the format of a date are supported with the use of functions.

\paragraph{Alternatives:}
The evolution specification is defined alongside the contract specification in the same manifest file.
Most web API specification languages already support default values and name aliases.
With these two features it would be straightforward
to document the following contract evolutions: renamed fields, addition of fields and removal of fields.
This alternative may seem appealing for simpler contracts, but it becomes impractical as the number of revisions and consumers in prior versions rises.
This approach clutters service contract's with information that is irrelevant to consumers, and makes the specification of complex contract evolutions more cumbersome.

\subsection{Adapter Location} % (fold)
\label{sec:adapter_location}

The adaptation of messages is supported at runtime by a generated proxy component
that dynamically adapts the data exchanged between services.
The adapter can be deployed and intercept messages in different points through the exchange.

\paragraph{Approach:}
The adapters are installed as side-car container on the same node as the producer service container.
Consumers direct their requests based on the expected version of the service using a routing rule.
If the expected version matches the current service version, the request is answered directly by the service;
otherwise, the request is redirected through the adapter.
Since the adapter and the service are in the same node, the communication cost is expected to be comparable to the cost of inter-process message passing.
The main benefit of this approach is that the adapter can be deployed alongside the service,
which circumvents distributed transactions in deployments,
because container orchestrations tools such as kubernetes allow the deployment of closely related containers as atomic units known as "pods".

\paragraph{Alternatives:}
The generated adapter code can be embedded in the service implementation.
This approach is expected to have higher performance than the previous approach since
the adapter would use function calls instead of inter-process calls, and because message serialization and de-serialization would be unnecessary.
The downside of this approach is that it would entail the modification of the service's code, which is problematic because each service can be implemented in a different framework and programming language.

\paragraph{}

Alternatively the adapter can be installed on the nodes of all the consumers of a producer service.
This approach is problematic because a service upgrade would entail the re-deployment of all consumers.
If one of the consumer re-deployments fails, the entire service upgrade would have to be cancelled;
this is only achievable with the use of distributed transactions, which are inherently complex.
The re-deployment of consumers pods due to the installation of adapters can be avoided with the use of mobile code that is provided by the producer in a dedicated endpoint
(for example, this could be accomplished in Java with the use of network class loaders).
This approach is ineffective because it provides no benefits and requires more resources than the alternatives, since
instead of one adapter, N adapters would be needed, one for each consumer.

\subsection{Adapter Coverage} % (fold)
\label{sec:adapter_polymorphism}

The adapter can have a generic implementation that is able to adapt messages from any service, or it can
have a direct implementation that can only manage the adaptation of messages in one service.

\paragraph{Approach:}
The adapter implementation is derived from a template implementation,
that is completed with the substitution of template variables with code generated from evolution specification manifest file.
The advantage of this approach is that the implementation will be more performant than generic approaches.

\paragraph{Alternatives:}
The adapter has a generic implementation that is initialized with the data parsed from evolution specification files.
The correct adaptation procedure for a message is determined by inspecting specialized headers in the
message that indicate the message type, service and version.
The advantage of this approach is that a single adapter can convert messages from any service as long as the evolution manifests are supplied to the adapter beforehand.
This approach will consume fewer computational resources, in scenarios where the number of messages that require adaptation is low and uniformly distributed across all services,
because a single adapter can handle the load of all requests, whereas the alternative requires one adapter per service.
The disadvantage of this approach is that it requires modifications on the consumer's implementation to include message headers indicating the expected version of the producer service.

\subsection{Message Routing} % (fold)
\label{sec:message_routing}

Messages will need to reach either an application or an adapter, depending on the consumer expected contract, and the current producer contract.

\paragraph{Approach:}
The application and adapter servers of a microservice are accessible internally inside a cluster via distinct Kubernetes services.
A Kubernetes service, is an abstraction that defines a policy for accessing a logical set of containers under a single address.
For each version of a service contract a distinct Kubernetes service is created with the corresponding service name and contract version.
The address of each Kubernetes service is discoverable via an internal DNS server.
When a microservice is updated, all it's Kubernetes services are updated with the new addresses of application and adapter containers.
The Kubernetes service that previously pointed to the application containers, will now point to the adapter containers, and
a new Kubernetes service will be created to support the new contract.
All consumers of the previous contract will begin forwarding their requests to the adapter container's rather than the application containers.
Consumers that only use procedures that weren't affected in the contract evolution don't need to direct their calls through the adapter.
If optimal performance and resource consumption is desired,
such consumer services will have to be updated and redeployed with the new producer DNS name.
The redeployment of consumers in the former case can be avoided, if consumers participate in the contract evolution process.
The adapter server includes a header in responses that contains the address of the application server, and that indicates if a request required adaptation.
If the request didn't require modifications, consumer services begin to forward the request to the application server instead of the adapter.
With this approach consumer services are no longer unaware of the existence of proxy adapters,
and will need to use different addresses when calling different procedures of the same producer service.

\paragraph{Alternatives:}
A reverse proxy like nginx could be used to route only the messages that require adaptation through the adapter.
With this approach all requests are forwarded through reverse proxy and redirected based on custom routing rules.
The routing rules are installed and updated when contract implementations are deployed.
This approach is counter-productive since it necessitates an additional reverse proxy server,
which will use roughly the same computational resources and add the same latency as the adapter server.

\subsection{Adapter Management} % (fold)
\label{sec:adapter_management}

The management of adapters should be automated similarly to the management of services.
In this section, we discuss how to conciliate the operations related to the management of adapters with the more common operations of service deployment and upgrade.

\paragraph{Approach}
During normal operation the adapters don't require any type of management other than monitoring,
adapters components only need to be provisioned during the upgrade of service contracts.
A contract upgrade is supported by the re-deployment of the impacted microservice, which is often managed via a continuous deployment pipeline.

We propose to introduce the operations of contract compatibility verification, adapter generation, deployment,
and removal as additional stages in typical continuous deployment pipelines.
The generation of the adapter components could be preformed outside the deployment pipeline,
this would increase the solution flexibility by allowing developers to manually extend adapters to cover unforeseen corner cases,
however, it is preferable to generate the adapters in the pipeline so that adapter generation program has clearer view
over the participating services in the system.

\subsection{Supported Changes} % (fold)
\label{sec:supported_changes}

"Message Split Mismatch"
In order to keep the adapter implementation as lightweight as possible, it is preferable to maintain the old endpoint operational but marked as deprecated, and provide the new endpoints in conjunction with the old endpoint.

"Message Merge Mismatch"
It is preferable to keep the old endpoints operational but marked as deprecated, and provided the new endpoint in conjunction with the old endpoints.
